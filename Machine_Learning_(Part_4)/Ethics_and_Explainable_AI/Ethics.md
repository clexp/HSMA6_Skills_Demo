## Ethics in AI

Machine learning models may learn inherent biases in data. This means their classifications could be offensive or even dangerous. They may represent racial bias or misclassify causing wrongful arrest.

There may be racial biases or gender biases. Data sets may disproportionately represent certain groups. Data sets may train models in adequately on some minorities.

Where data is the whole body of the Internet, it may include toxicity bias prejudices.

This may appear in outputs.

There may be racial biases or gender biases. Data sets may disproportionately represent certain groups. Data sets may train models in adequately on some minorities.

Where data is the whole body of the Internet, it may include toxicity bias prejudices.

This may appear in outputs.

### What can we do?

- Make sure your data has an appropriate balance between different people groups
- Make sure your data is clean from toxic language
- Make sure your data is not over representative.
- Make sure your data is not over representative.
- Make sure your data has real wild examples
- Test the model works well for all people groups and all languages
- Put measures in place to handle failure cases
- Can you explain your model?

## Transparency

Transparency refers to being fully open about how you built the model. If you can explain how you collected data, how you selected data, how you cleaned and filtered data you can indicate which biases you did include or exclude. If you can be clear about how you test the model when trained, then you can answer difficult questions about which biases are now no longer present in the model.

## consequence

When it goes wrong, it really goes wrong. The man beaten by police for a bad image recognition. AI is designed to automate. If there are mistakes, they will be automated, and made at scale.
